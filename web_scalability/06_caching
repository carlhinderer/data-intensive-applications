-----------------------------------------------------------------------------
| CHAPTER 6 - CACHING                                                       |
-----------------------------------------------------------------------------

- Caching

    - Caching is winning the battle without the fight.  It can be used to increase performance and
        scalability at low cost, without having to recompute responses.


    - Caching is a very popular technique in computer science.  Here are a few examples:

        - CPU caches
        - Hard drive caches
        - Linux OS file caches
        - database query caches
        - DNS caches
        - HTTP browser caches
        - HTTP proxies and reverse proxies
        - different types of application object caches


    - Instead of fetching data and computing a response every time a request is received, we can build
        the result once and store it in the cache.  Subsequent requests are satisfied by returning the
        cached result until it expires or is explicitly deleted.



- Cache Hit Ratio

    - Three main factors affect your cache hit ratio:

        1. Data set size
        2. Space
        3. Longevity


    - Your cache key space is all the possible unique keys your application could generate.  The more
        unique keys your application generates, the less chance you have to use any one of them.

      If you want to cache weather forecast data based on the client's IP, you would have 4 billion 
        possible cache keys.  If you cache the weather forecast based on country, you have less than
        300 keys.  The fewer possible keys, the better the cache efficiency.


    - The second factor is the number of items you can store in your cache without running out of
        space.  This depends on the size of the cache and the size of the items.

      Because caches are usually stored in memory, space is relatively limited and expensive.  If you
        run out of space, you'll have to evict entries before you can add new ones.  The more objects
        you can fit in your cache, the better your cache hit ratio.


    - The third factor is how long, on average, each object can be stored in the cache without 
        expiring or being invalidated.

      In some caches, you can cache objects for a predefined amount of time using TTL.  However, in
        other cases, you may not be willing to serve stale data.  For instance, if prices are changed
        in an ecommerce site, we cannot show the old prices, so we have to invalidate the cache
        entries.


    - Use cases with a high read-to-write ratio are usually good candidates for caching.



- Caching Based on HTTP

    - The HTTP protocol has been around for a long time, and over the years the specification has
        changed to allow different parts of the infrastructure to cache HTTP responses.

      This makes HTTP caching a bit more difficult to understand, and it's also the reason there are
         many different HTTP headers related to caching (and even some HTML metatags!).


    - All HTTP layer caches are 'read-through caches'.  A read-through cache is a caching component
        that can return cached data or fetch data from the client if necessary.

      This means that the client connects to the read-through cache, rather than the origin server
        that generates the actual response.


    - The cache is always meant to be an intermediate (aka a 'proxy'), transparently adding caching
        functionality to HTTP connections.  Clients are not able to distinguish whether they received
        a cached object or not.



- HTTP Headers

    - Simple HTTP request:

        # Request
        GET / HTTP/1.1
        Host: www.example.org
        Accept-Encoding: gzip,deflate
        Connection: keep-alive

        - 'Accept-Encoding: gzip,deflate' defines which compressed data encodings browser supports
        - 'Connection: keep-alive' means that server should keep TCP connection open for addl downloads


    - And here is the response:

        # Response
        HTTP/1.1 200 OK
        Content-Encoding: gzip
        Content-Type: text/html; charset=UTF-8
        Content-Length: 9381
        Connection: close

        ... response body with contents of the page ...

        - 'Content-Encoding: gzip' indicates the server decided to return a gzip response
        - 'Connection: close' means the client's request to keep the connection open was rejected



- The 'Cache-Control' Header

    - The 'Cache-Control' header was added to the HTTP/1.1 spec and is now supported by most browsers
        and caching packages.  Cache-Control allows you to specify multiple options:

        Cache-Control: no-cache, no-store, max-age=0, must-revalidate


    - The most important Cache-Control options that web servers may include in their responses:

        private                # Private to user that requested it, cannot be served to any other user

        public                 # Can be shared among users as long as not expired

        no-store               # Response should not be persisted to disk (for sensitive information)

        no-cache               # Response should not be cached (means that cache should always ask server)

        max-age                # How many seconds response can be served from cache before becoming stale
                               #   (defines TTL of response)

        no-transform           # Includes response should be served without modifications

        must-revalidate        # Once response becomes stale, it cannot be returned to clients without
                               #   revalidation


    - A cached object is 'fresh' until it's expiration time passes.  After that, it becomes 'stale',
        but can still be returned to clients if they explicitly allow stale responses.

    - Clients can also use the 'Cache-Control' header in requests, but it is rarely used and has
        slightly different semantics.



- The 'Expires' Header

    - The 'Expires' header allows you to specify an absolute point in time when the object becomes
        stale.

        Expires: Sat, 23 Jul 2015 13:14:28 GMT


    - Unfortunately, setting the TTL in multiple different headers leads to confusion and inconsistent
        behavior.  So, it's a best practive to set it in one place and stick with it.



- The 'Vary' Header

    - The 'Vary' header tells caches that you may need to generate multiple variations of the response
        based on some HTTP request headers.

      The most common use for this is to indicate that clients that support gzip will get a 
        compressed response, while clients that don't support gzip will not.

        Vary: Accept-Encoding



- First Caching Scenario - Cache a Response Forever

    - We want to use this technique for all static content.  Static content files should be considered
        immutable.  If we need to change them, we should create a new URL.

      For instance, you can bundle and minify your CSS files, then include a timestamp or hash of the
        contents in the URL.


    - This way, the files can always be cached safely by any server.  Users won't get stale versions,
        since clients with the new version will point to a new URL.


    - Even if we intend to cache files forever this way, we still shouldn't set the 'Expires' header 
        for more than a year in the future (since the HTTP spec doesn't allow it).

        # Headers for static asset, expires one year from now
        Cache-Control: public, no-transform
        Expires: Sat, 23 Jul 2016 13:14:28 GMT
        Vary: Accept-Encoding



- Second Caching Scenario - Content that is Never Cached

    - In this case, we want to make sure the HTTP response is never stored, cached, or reused for any
        users.  We have included the 'Pragma: no-cache' header also, so that older clients can 
        understand the intention of not caching the response.

        Cache-Control: no-cache, no-store, max-age=0, must-revalidate
        Expires: Fri, 01 Jan 1990 00:00:00 GMT
        Pragma: no-cache



- Third Caching Scenario - Cache for a User Only

    - In this case, we want to cache responses for a given user only.  For instance, we want to cache a
        user's profile page for that user.


    - We can still use the full page cache, but it will have to be a private cache to ensure users only
        see their own pages.

        Cache-Control: private, must-revalidate
        Expires: Sat, 23 Jul 2015 13:14:28 GMT
        Vary: Accept-Encoding



- Using HTML Metatags for Caching

    - There are some old HTML meta tags for caching.  It is best to avoid using them altogether.

        <meta http-equiv="cache-control" content="max-age=0" />
        <meta http-equiv="cache-control" content="no-cache" />
        <meta http-equiv="expires" content="Tue, 01 Jan 1990 1:00:00 GMT" />
        <meta http-equiv="pragma" content="no-cache" />



- Types of HTTP Cache Technologies

    - There are 4 main types of HTTP caches:

        1. Browser cache
        2. Caching proxies
        3. Reverse proxy
        4. Content delivery networks



- Browser Caches

    - All modern browsers have some kind of cache, which usually uses a combination of memory and local
        files.

    - Whenever an HTTP request is about to be sent, the browser can check the cache for a valid version
        of the resource.  If the item is present and not expired, it can be resued without having to
        send the request.



- Caching Proxies

    - A 'caching proxy' is a server usually installed in a local corporate network or by an ISP.  It
        is a read-through cache used to reduce the amount of traffic generated by the users of the 
        network by reusing responses.


            [Office Building]                       [Data Center]

             Client
                |
                v
            HTTP Proxy Server   ->   Internet   ->   Web Server


    - The larger the network, the bigger the potential savings.  This is why it was quite commong among
        ISPs to install transparent caching proxies, then route all HTTP traffic through them to cache
        as many requests as possible.

    - In recent years, installing local proxy servers has become less popular, as bandwidth becomes
        cheaper and more websites serve all resources over SSL (so cannot be intercepted by proxy).



- Reverse Proxy

    - A 'reverse proxy' works just like a regular caching proxy, but the intent is to place it in your
        own data center to reduce load put on your web servers.

            [Office Building]                   [Data Center]

             Client    ->    Internet    ->     HTTP Proxy Server
                                                       |
                                                       v
                                                  Web Server


    - For some applications, reverse proxies are an excellent way to scale.  They also give you more
        flexibility, since they can override HTTP headers for better control over which requests get
        cached and for how long.


    - Reverse proxies are also a great way to scale your web services layer, since the results of
        the REST requests can also be cached.


        Client  ->  Front-end Web Server  ->  Reverse HTTP Proxy  ->  Web Services



- Content Delivery Networks

    - A CDN is a distributed network of cache servers that work in a similar way to caching proxies.
        They depend on the same HTTP headers, but they are controlled by the CDN service provider.

    - By using a CDN, you reduce load on your own servers, save on network bandwidth, and improve 
        the user experience.  



- Scaling HTTP Caches

    - Scaling browser caches, third party proxy caches, or CDNs is out of our control.  We can scale
        out reverse proxy servers.


    - Popular Open Source Reverse Proxy Solutions:

        - Nginx
        - Varnish
        - Squid
        - Apache mod_proxy
        - Apache Traffic Server


    - The most common method for evicting old cache entries is 'Least Recently Used' (LRU), which allows 
        the cache server to eventually remove rarely accessed objects and keep hot items in memory to
        maximize cache hit ratio.


    - Here is an example of using 2 layers of reverse proxies to scale:

                                      External Traffic
                                              -
                                              v
                --------------------------------------------------------------
                [Data Center]          Load Balancer
                                         |       |
                                         v       v
                                    Reverse Proxy Servers
                                         |       |
                                         v       v
                                     Front End Servers
                                         |       |
                                         v       v
                                   Reverse Proxy Servers (caching and load balancing)
                                         |       |
                                         v       v
                                        Web Services


    - Note that the caching layer for the front-end servers is often a CDN.



- Nginx

    - Nginx is a good general purpose reverse-proxy solution.

    - Uses asynchronous processing, which allows it to proxy tens of thousands of concurrent 
        connections with a very low per-connection overhead.

    - Nginx is also a FastCGI server, which means you can run your web application on the same web
        server stack as your reverse proxies.

    - Nginx can act as a load balancer.  It supports multiple forwarding algorithms and many advanced
        features, such as SPDY, WebSockets, and throttling.  It can also override headers to change
        caching behavior.
        