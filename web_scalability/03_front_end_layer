-----------------------------------------------------------------------------
| CHAPTER 3 - BUILDING THE FRONT-END LAYER                                  |
-----------------------------------------------------------------------------

- The Front-End Layer

    - Front-end components receive the most traffic and have the highest concurrency demands.

    - Types of front end applications:
        1. Traditional multipage web apps = entirely implemented in server-side framework
        2. SPAs = built in JS, call an API layer, partial loading using AJAX
        3. Hybrid = some interactions cause full reload, some just AJAX actions



- Managing HTTP Sessions

    - Sessions are implemented using cookies.  When a web server receives a request, it can add a session
        cookie to a response, then that cookie will be included in all consecutive calls.

    - This ability to track which requests came from which user allows login functionality and other
        similar features.

    
    - When you log into a website, the web application stores your user id and additional data in the web
        session scope.  The web framework is responsible for storing this web session scope 'somewhere', 
        then making it available during handling of HTTP requests.

      There are 3 common ways to solve this problem:
        1. Store session state in cookies
        2. Delegate session storage to an external data store
        3. Use a load balancer that supports sticky sessions



- Storing Session State in Cookies

    - Just before sending a response to the client, your framework serializes the session data, encrypts
        it, and includes it in the response headers as a new value of the session data cookie.

    - You do not have to store session data on the server side using this approach.  The entire session
        state is handed to you with every web request.

    - This is expensive, since it is sent with every request.  Browsers will send the full cookies on 
        every image or CSS file download and every AJAX request.

    - This approach works well if you have a small amount of data like a user id or security token.

    - We have to encrypt the serialized session data, then base-64 encode it, which is a further
        inefficiency that raises the byte count of the session data by 30%.



- Storing Session State in a Dedicated Data Store

    - In this case, the web server takes the session identifier from the web request and then loads
        session data from an external store.

    - At the end of a request cycle, the web server saves the session state to the data store just
        before sending a response to a client.

    - Memcached, Redis, DynamoDB, and Cassandra are commonly used for this purpose.  It needs to be
        a key/value store with low latency.



- Storing Session State with Sticky Sessions

    - The load balancer inspects the headers of the request to make sure that requests with the same
        session cookie always always go to the server that initially issued the cookie.

    - Any time a new client makes a request, it injects a new load balancer cookie into the response.

    - This approach is generally avoided, since it breaks the fundamental principle of statelessness.
        You will not be able to restart, decommission, or safely auto-scale web servers without
        breaking user's sessions.  Also, people will put non-session data there for convenience,
        which is even worse.



- Managing Files

    - The second most common type of state in web applications for front-end servers is file storage.
        There are 2 types of files to pay attention to:

        1. User-generated content being uploaded to your servers
        2. Files generated by your system that need to be downloaded by the user


    - AWS S3 or Azure Blob Storage are good cheap solutions, especially if it doesn't make sense to
        store all your files internally.

    - It's always a good idea to use a CDN, regardless of how your files are stored.

    - With AWS, you can select a public bucket, and S3 will serve the files for you directly.  Or,
        you can select a private bucket, and your web server will download the files from S3 instead.

    - Building a true fully-featured file store for yourself is tricky and expensive.  Try to use an
        open source component instead.



- Managing Other Types of State

    - Local server cache inconsistensies and application in-memory state can be other sources of
        problems when scaling.  The solution is to used some kind of shared object cache.

    - Resource locks on shared distributed resources can also be a problem.  To solve this, we should
        remove the lock and deploy that resource as an independent service.  ZooKeeper can be used as
        a service to keep track of locks.



- DNS

    - Typically best to use a hosted third party service
    - Use Route 53 if on AWS (Also has GeoDNS-like features)
    - Connects clients to load balancer



- Load Balancers

    - Necessary to hide complexity from clients
    - Can easily perform maintenance and rolling updates
    - Can handle scaling and high availability

    - Can use SSL offloading (aka SSL termination), which has load balancer do all encryption/
        decryption, then passes data around unencrypted internally (subject to security compliance)

    - Use ELB if on AWS (cheap, autoscaling, high availability, SSL termination, manage with SDK)



- Self-Managed Software-Based Load Balancer

    - If you can't use a hosted load balancer service, you may want to use one of the open source
        software-based load balancers.  The most popular are:

        1. Nginx = a reverse proxy
        2. HAProxy = a specialized load balancer product


    - The advantage of Nginx is that it is also a reverse HTTP proxy, so it can cache HTTP responses
        from your servers.  This makes it a great candidate for an internal web service load
        balancer.  The caching can reduce strain on web services.

    - HAProxy ('High Availability Proxy') is just a load balancer.  It can be used for any protocol, 
        not just HTTP/HTTPS.  It can be configured as a Layer-7 load balancer, supporting SSL 
        termination and sticky sessions.
    
    - Both Nginx and HAProxy can handle thousands of requests from hundreds of concurrent users per
        second.



- Hardware Load Balancers

    - These are high-end devices for high-traffic websites that host their own physical data centers.
    - Extremely high high throughput and low latency



- Web Servers

    - Usually makes sense to use fully featured web framework and web server like Apache
    - Node.js might make the most sense for something like a chat app
    - Most important thing is to keep things stateless so that they're easy to scale



- Caching

    - CDN is a form of cache
    - Reverse proxy servers like Varnish and Nginx cache HTTP responses
    - Can cache a small amount of data in the browser
    - Shared object cache like Redis or Memcached cache fragments of responses



- Auto-scaling

    - Auto-scaling is adding or removing servers to the cluster based on traffic volume.
    - Easiest way is to use tools provided by hosting company like AWS, Rackspace, Azure

    - AWS Auto-scaling
        > Need to use EC2 instances for web servers
        > Cannot store data on web servers
        > Shutting down servers should not cause broken user experience
        > Configure AMI (Amazon Machine Image) so that new servers can bootstrap themselves and join
        > AWS Cloud Watch collects metrics used for scaling policies



- Deployment Example - AWS

    - You are responsible for managing EC2 instances, although they have tooling
    - Route 53 is used as DNS
    - ELB is used as load balancer
    - Web servers (EC2 instances) handle web requests
    - All files are stored in S3
    - On the way back to the client, responses may be cached by CloudFront



- Deployment Example - Private Data Center

    - DNS and CDN are offloaded to 3rd party services
    - This approach lets you control latency, cost, and security and legal requirements
    - Need to plan scaling ahead of time