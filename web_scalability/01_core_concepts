-----------------------------------------------------------------------------
| CHAPTER 1 - CORE CONCEPTS                                                 |
-----------------------------------------------------------------------------

- What is scalability?

    - Scalability = ability to adjust capacity of system to cost-effectively fulfill demands

    - Handling more data
    - Handling higher concurrency levels
    - Handling higher interaction rates

    - Need to scale organizational structures as well.  Having more than 8-15 people on a single
        team becomes inefficient as communication overhead grows.



- Evolution from Single Server to Global Audience

    1. Single-server configuration

         - DNS is paid service provided by hosting company, mapped to server's IP
         - Single server has DBMS, application stack, static assets


    2. Scaling the server vertically

        - Add more I/O capacity by adding hard drives in RAID arrays

        - Improve I/O access times by switching to SSDs 
            > Note that random r/w 10-100x faster, sequential r/w not much better
            > Most RDBMS use algorithms for maximizing sequential disk reads
            > Cassandra uses solely sequential I/O for all writes and most reads

        - Reduce I/O operations by increasing RAM
        - Upgrade NICs (especially for audio/video content)
        - More processors/cores


    3. Isolation of services

        - Put web server and DB server on separate machines
        - Can put DNS, FTP, cache, etc. on separate machines
        - Functional partitioning


    4. CDN for static content

        - CDN = hosted service for files like images, JavaScript, CSS, videos
        - Clients connect to CDN instead of your servers for files
        - If the CDN doesn't have the requested content, it will download from your servers
        - Good locality, since big CDN providers are spread across the world


    5. Horizontal scalability 

        - Much harder to achieve, need to think about this before building
        - Run on cheap commodity machines
        - Use something like Round-robin DNS to distribute traffic among web servers
        - True horizontal scalability is difficult and expensive
        - Start with easy things like web servers and caches, then move to databases and persistence


    6. Scalability for a global audience

        - Need global distribution for better user experience and failure recovery
        - Can use GeoDNS, which resolves name to IP based on location

        - Can have edge-cache servers located around the world to further reduce latency
            > Edge cache = HTTP cache server located near the customer
            > Requests from customer's browser go to edge cache server
            > Server decides to assemble page from cache, send requests to your web servers, or delegate



- Overview of Data Center Infrastructure

    1. The front line

        A. Client requests go to GeoDNS to resolve domain names

        B. GeoDNS decides which data center is closer and responds with IP of load balancer
              (usually strong hardware load balancer)

        C. Traffic gets distributed either to front end cache servers (optional) or front-end web
              application servers.


    2. Web application layer

        - Web application servers responsible for generating the actual HTML of our applications and
            handling clients' HTTP requests.

        - Usually use lightweight web framework with minimal amount of business logic, since their
            primary responsibility is rendering the user interface.  Should just handle user
            interactions and push most business logic to web services layer.

        - Should be completely stateless, so just add more servers to load balancer to scale


    3. Web services layer

        - Contains most application logic
        - Scale by creating functional partitions with specific responsibilities
        - Communication between front-end applications and web services is usually REST
        - As long as no shared state, easy to scale
        - Many webservices are provided stand-alone without a UI in front of them nowadays


    4. Additonal components

        - Object cache servers are used to speed up reads by storing precomputed results
        - Message queues are used for asynchronous processing


    5. Data persistence layer

        - Era of polyglot persistence
        - Often now includes search component



- Overview of Application Infrastructure

    - Architecture should always revolve around the business model (domain-driven design)

    - Front end = should be presentation only

    - Web services = SOA, layered, hexagonal, EDA architecture principles
        > SOA = loosely coupled and highly autonomous services
        > Layered = each layer can only depend on layers below it
        > Hexagonal = business logic is the center and all other systems revolve around it
        > EDA = react to events instead of request/response

    - Abstract the data store from other code, so it can be changed if necessary

    - Purpose of architecture: 
        > Build higher abstractions that hide complexity
        > Limit dependencies
        > Allow you to scale each part independently
        > Make parallel development of different parts practical