----------------------------------------------------
CHAPTER 1 - KEY PROJECT TYPES AND CONSIDERATIONS
----------------------------------------------------

- Major Data Project Types

    1. Data Pipelines and Data Staging

         These are ETL-type projects that provide the basis for performing subsequent analysis and
           processing of data.


    2. Data Processing and Analysis

         These are projects that end in providing some kind of actionable value, like the creation of
           reports or machine learning models.


    3. Applications

         These are data frameworks meant to support live operational needs of applications, like the
           data backends for web or mobile applications.



- Aspects of the Project Types

    1. Primary Considerations

         Each of the 3 project types have distinctions that will affect architectural decisions and 
           priorities.  The decisions will drive the rest of the project.  


    2. Risk Management

         Each project type has a set of associated risks.  There are often multiple approaches to risk
           management based on specific use cases.


    3. Team Makeup

         The types of skills, experience, and interests will vary with the different project types, so
           we provide some recommendatations around building successful teams for each project type.


    4. Security

         Security is an extensive and important topic we can't go into a ton of detail on here, but 
           we'll enumerate the security concerns we need to keep in mind throughout our projects.



- Fundamental Security Dimensions

    1. Authentication

         This involves ensuring that users accessing the system are who they claim to be.  Any mature
           system should offer support for strong authentication.  This is typically done with an
           authentication protocol like Kerberos or LDAP.


    2. Authorization

         After ensuring that a valid user is accessing a system, we need to determine which data they're
           allowed to access.  A mature system will allow access to be controlled at different levels
           of granularity, such as at both the table-level and column-level.  


    3. Encrpytion

         We encrypt data to protect it from malicious users and intrusions.  We need to consider this from
           2 different angles:

           - Data at rest = This is data stored on disk.  Many vendors have solutions for managing this.

           - Data on the wire = This is data moving through the system.  Generally, this is supported via
               standard encryption mechanisms like TLS.


    4. Auditing

         We must be able to capture activity related to data in our system, including the lineage of the
           data, who is accessing it, how it is being used, and so on.  Again here, many vendors offer
           tools to manage this.



- Project Type #1: Data Pipelines and Data Staging

    - This project type has the widest scope of the 3, because it involves the path from external data
        sources to destination data sources, and will provide the basis for building out the rest of
        our data use cases.


    - We need to design our solution with these things in mind:

        1. Types of queries, processing, and so on that we'll be performing against the destination data

        2. Any customer-facing data requirements

        3. Types of data collected in terms of its value


    - It is crucial that we pay careful attention to modeling and storing the data in a way that 
        facilitates further access.


    - Primary Concerns and Risk Management

        1. Consumption of source data

        2. Guarantees around data delivery

        3. Data governance

        4. Latency and confirmations of delivery

        5. Access patterns against the destination data



- Source Data Consumption

    - Sources can be anything from phones, sensors, applications, machine logs, operational and
        transactional databases, etc.  The source itself is mostly out of scope of your pipeline and
        staging use cases.  

      In fact, you can evaluate the success of your scoping by how much of your time you spend working 
        with the source team.  The less time your data team spends with the source team, the better the
        source integration is designed.


    - There are several standard approaches used for source data collection:

        1. Embedded Code

             This is when you provide code embedded within the source system that knows how to send 
               required data into your data pipeline.


        2. Agents

             This is an independent system that is close to the source and in many cases is on the same
               device.  This is different from the embedded code approach, because the agents run as 
               separate processes with no dependency concerns.


        3. Interfaces

             This is the lightest of the options.  Examples include REST or Websocket endpoints that
               receive data sent by the sources.


        4. Other Options

             There are other commonly used options to perform data collection.  For example, there are
               third party data integration tools, either open source or commercial.  

             Also, there are batch ingest tools such as Apache Sqoop or tools provided with specific
               projects, such as the HDFS 'put' command.



- Source Data Consumption: Embedded Code

- Source Data Consumption: Agents

- Source Data Consumption: Interfaces