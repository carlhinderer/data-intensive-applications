
[Contents]

Part 1: Foundations of Data Systems

  1. Introducing Terminology
     Discussion of Reliability, Scalability, and Maintainability

  2. Comparison of Different Data Models and Query Languages
     Databases from a Developer's Point of View

  3. Internals of Storage Engines and How Databases Lay Out Data on Disk

  4. Various Formats for Data Encoding (Serialization)
     How the Different Formats Fare When Schemas Change Over Time


Part 2: Distributed Data
        What Happens If Multiple Machies Are Involved With Storage and Retrieval of Data

  5. Replication
     Having Multiple Copies of the Data on Different Nodes

  6. Partitioning
     The Need to Break Up Large Datasets Into Partitions (aka Sharding)

  7. Transactions
     Issues With Grouping Several Reads and Writes Together Into a Logical Unit

  8. Problems With Distributed Systems
     Hardware Failures, Unreliable Systems, Unreliable Clocks

  9. Consistency and Consensus
     Examples of Algorithms and Protocols For Building Distributed Systems
     Seek Abstractions That Can Allow an Application to Ignore Distributed System Problems


Part 3: Derived Data
        Integrating Multiple Different Data Systems Into a Coherent Architecture
        
  10. Batch-Oriented Dataflow Systems
      MapReduce

  11. Data Streams
      Processing Data With Shorter Delays

  12. The Future of Data Systems
      How We Can Improve Design



1. Reliability, Scalability, Maintainability

     - Reliability against hardware failure, software failure, and human error
     - Describing Performance
     - Coping With Load By Scaling
     - Operability, Simplicity, and Evolvability


2. Data Models and Query Languages

     - The long dominance of relational models
     - The document model
     - Sql
     - MapReduce Querying
     - Querying Graph Databases


3. Storage and Retrieval

     - Very Simple bash Database
     - Log Structures
     - Hash Indexes
     - SSTables
     - Making LSM-Trees Out of SSTables
     - BTrees
     - OLTP vs OLAP
     - Data Warehousing
     - Star and Snowflake Schemas
     - Column-Oriented Databases


4. Encoding Data

     - Encoding (aka Serializing or Marshaling) Data
     - Language Specific Formats
     - JSON, XML, and CSV
     - Binary Encoding Formates Like MessagePack
     - Thrift and Protocol Buffers
     - Apache Avro
     - Schemas and Schema Evolution
     - Dataflow Through Databases
     - Dataflow Through Services

     - Dataflow Through Message Passing

         - Messages are not sent directly via network connection (like services), but go through an 
             intermediary called a 'message broker' (aka a 'message queue'), which stores the
             message temporarily.  

         - Benefits of Using a Broker:

             1. It can act as a buffer if the recipient is unavailable or overloaded
             2. It can automatically redeliver messages to a process that has crashed
             3. It avoids the sends needing to know the IP address and port of every recipient
             4. It allows one message to be sent to several recipients
             5. It logically decouples the sender from the recipient

         - Common Message Brokers:

             - Companies TIBCO, IBM Websphere, webmethods
             - Open Source RabbitMQ, ActiveMQ, HornetQ, NATS, Apache Kafka

         - Broker Operation

             1. One process sends a message to a named 'queue' or 'topic'

             2. The broker ensures the message is delivered to one or more 'consumers' or 'subscribers'


5. Replication

    - Replication vs Partitioning

        - Replication = Keeping a copy of the same data on several different nodes, potentially in 
            different locations

        - Partitioning (aka Sharding) = Splitting a big database into smaller subsets called partitions
            so that different partitions can be assigned to different nodes

    - Reasons to use partitioning:

        1. Keep data geographically close to users
        2. Fault tolerance
        3. Scale out the number of machines that can serve read queries


    - Leaders and Followers

    - Problems with Replication Lag

    - Multi-Leader Replication

    - Leaderless Replication



6. Partitioning

     - Partitioning and Replication

     - Partitioning of Key/Value Data

     - Partitioning and Secondary Indexes

     - Rebalancing Partitions

     - Request Routing



7. Transactions

     - The Slippery Concept of a Transaction

     - Weak Isolation Levels

     - Serializability



8. The Trouble With Distributed Systems

     - Faults and Partial Failures

     - Unreliable Networks

     - Unreliable Clocks

     - Knowledge, Truth, and Lies



9. Consistency and Consensus

     - Consistency Guarantees

     - Linearizability and CAP Theorem

     - Distributed Transactions and Consensus



10. Batch Processing

     - 3 Different Types of Systems:

         1. Services (online systems) = A service waits for a request or instruction from a client to arrive.
              When one is received, the service tries to handle it as quickly as possible and sends a response
              back.  Response time is usually the primary measure of performance of a service, and availability
              is often very important (if the client can't reach the service, a user will get an error message).

         2. Batch Processing Systems (offline systems) = A batch processing system takes a large amount of 
              input data, runs a 'job' to process it, and produces some output data.  Jobs often take a while
              (several minutes to several days), so there normally isn't a user waiting for the job to finish.
              Instead, batch jobs are often scheduled to run periodically.  The primary performance is usually
              throughput (the time it takes to crunch a dataset of a certain size).

         3. Steam Processing Systems (near real-time systems) = Stream processing is somewhere between online
              and batch processing.  Like a batch processing system, a stream processor consumes inputs and
              produces outputs (rather than responding to requests).  However, a stream job operates on events
              shortly after they happen, whereas a batch job operates on a fixed set of input data.  This
              difference allows stream processing systems to have lower latency than batch systems.